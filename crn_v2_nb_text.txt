{"cells": [{"cell_type": "markdown", "id": "md00", "metadata": {"trusted": true}, "source": "# CRN Baseline v2 — Aligned-Crop STFT Speech Enhancement\n\n## Critical Bug Fix from v1\n**v1 had a fatal data-loading bug:** `_load_fix()` was called independently for noisy and clean files —\neach call generated its OWN random crop position.  Since WAV files are 16–24 seconds long and we crop\n3-second segments, the noisy and clean waveforms came from **completely different time positions** in the\nutterance.  The model was training on mismatched (noisy segment A, clean segment B) pairs.\n\n**Evidence:** v1 noisy baseline had STOI = 0.215 and SI-SDR = −44 dB — indicating the \"pairs\" were\nessentially unrelated audio.\n\n**Fix:** `__getitem__` now computes **one** random start position and applies it to **both** files.\nFor test evaluation, `start = 0` (deterministic) so metrics are fully reproducible.\n\n**Architecture:** CRN (Conv-Recurrent Network)\n```\nInput: (B, 1, 257, T) ← log1p(STFT magnitude)\n  → CNN Encoder (3 layers, stride-2 on freq): (B, 256, 33, T)\n  → Reshape → LSTM(256, hidden=256, 2 layers) across time per freq-bin\n  → CNN Decoder + Sigmoid → mask (B, 257, T)\nReconstruction: mask × noisy_mag → ISTFT with noisy phase → waveform\n```\n\n**Team:** Krishnasinh Jadeja (22BLC1211), Kirtan Sondagar (22BLC1228), Prabhu Kalyan Panda (22BLC1213)\n**Guide:** Dr. Praveen Jaraut — VIT Bhopal Capstone"}, {"cell_type": "code", "execution_count": null, "id": "c01", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 1: Install deps + Imports + Config\n# ============================================================================\n!pip install pesq==0.0.4 pystoi -q\n\nimport torch, torch.nn as nn, torch.nn.functional as F\nimport torchaudio\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport glob, os, json, time, warnings\nwarnings.filterwarnings('ignore')\nfrom pesq import pesq as pesq_metric\nfrom pystoi import stoi as stoi_metric\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# STFT config\nN_FFT      = 512\nHOP_LENGTH = 256\nN_FREQ     = N_FFT // 2 + 1   # 257\nSR         = 16000\nMAX_LEN    = 48000             # 3 s crop from 16-24 s files\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Device: {device}')\nif device == 'cuda':\n    props = torch.cuda.get_device_properties(0)\n    vram = getattr(props, 'total_memory', getattr(props, 'total_mem', 0))\n    print(f'GPU: {torch.cuda.get_device_name(0)} | VRAM: {vram/1e9:.1f}GB')\nprint(f'STFT: n_fft={N_FFT}, hop={HOP_LENGTH}, freq={N_FREQ}')\nprint(f'MAX_LEN={MAX_LEN} ({MAX_LEN/SR:.1f}s crop)')\nprint('Imports OK')"}, {"cell_type": "markdown", "id": "md02", "metadata": {"trusted": true}, "source": "## Dataset: LibriSpeech-Noise\nDownload & extract `earth16/libri-speech-noise-dataset` (7000 train + 105 test WAV pairs).\n\n**Files are 16–24 seconds** at 16 kHz.  We crop 3-second aligned segments for training."}, {"cell_type": "code", "execution_count": null, "id": "c03", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 2: Dataset download & extraction\n# ============================================================================\nimport subprocess, zipfile\n\ndata_base = '/kaggle/working/data'\ndl_tmp    = '/kaggle/working/dl_tmp'\nos.makedirs(data_base, exist_ok=True)\nos.makedirs(dl_tmp, exist_ok=True)\ndone_flag = os.path.join(data_base, '.done')\n\nif os.path.exists(done_flag):\n    print('Dataset already extracted, skipping')\nelse:\n    mounted = '/kaggle/input/libri-speech-noise-dataset'\n    if os.path.isdir(mounted) and len(os.listdir(mounted)) > 0:\n        src = mounted\n        print(f'Using mounted dataset at {src}')\n    else:\n        print('Dataset not mounted, downloading via kaggle API...')\n        subprocess.run(['kaggle', 'datasets', 'download',\n                        'earth16/libri-speech-noise-dataset', '-p', dl_tmp], check=True)\n        zf = os.path.join(dl_tmp, 'libri-speech-noise-dataset.zip')\n        if os.path.exists(zf):\n            with zipfile.ZipFile(zf, 'r') as z:\n                z.extractall(dl_tmp)\n            os.remove(zf)\n        src = dl_tmp\n        print(f'Downloaded to {src}')\n\n    subprocess.run(['apt-get', 'install', '-y', 'p7zip-full'], capture_output=True)\n    for arch in ['train.7z', 'y_train.7z', 'test.7z', 'y_test.7z']:\n        fp = os.path.join(src, arch)\n        if os.path.exists(fp):\n            print(f'Extracting {arch}...')\n            subprocess.run(['7z', 'x', fp, f'-o{data_base}', '-y'], capture_output=True)\n    open(done_flag, 'w').close()\n\ndef find_wav_dir(base, name):\n    for root, dirs, files in os.walk(base):\n        if os.path.basename(root) == name and any(f.endswith('.wav') for f in files):\n            return root\n    return None\n\nnoisy_train = find_wav_dir(data_base, 'train')\nclean_train = find_wav_dir(data_base, 'y_train')\nnoisy_test  = find_wav_dir(data_base, 'test')\nclean_test  = find_wav_dir(data_base, 'y_test')\n\nfor tag, d in [('noisy_train', noisy_train), ('clean_train', clean_train),\n               ('noisy_test', noisy_test), ('clean_test', clean_test)]:\n    n = len(glob.glob(os.path.join(d, '*.wav'))) if d else 0\n    print(f'  {tag}: {d} ({n} files)')\n\n# Sanity: check file durations (use torchaudio.load — .info() removed in newer versions)\nsample_files = sorted(glob.glob(os.path.join(noisy_test, '*.wav')))[:3]\nfor fp in sample_files:\n    wav, sr = torchaudio.load(fp)\n    num_frames = wav.shape[-1]\n    dur = num_frames / sr\n    print(f'  Sample: {os.path.basename(fp)} -> {dur:.2f}s ({num_frames} frames, sr={sr})')"}, {"cell_type": "markdown", "id": "md04", "metadata": {"trusted": true}, "source": "## STFT Dataset (ALIGNED Crops — CRITICAL FIX)\n\n**v1 bug:** `_load_fix()` called independently → noisy from time A, clean from time B.\n\n**v2 fix:** `__getitem__` loads BOTH, picks ONE random start, crops BOTH at same position.\nTest mode uses `start=0` for deterministic evaluation."}, {"cell_type": "code", "execution_count": null, "id": "c05", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 3: STFTSpeechDataset — ALIGNED crops (v2 fix)\n# ============================================================================\nclass STFTSpeechDataset(Dataset):\n    '''STFT dataset with ALIGNED random crops for noisy/clean pairs.\n\n    CRITICAL FIX: v1 generated independent random crops for noisy and clean,\n    meaning the model trained on mismatched audio segments.  Now we use ONE\n    shared crop position for both files.\n    '''\n    def __init__(self, noisy_dir, clean_dir, n_fft=N_FFT, hop_length=HOP_LENGTH,\n                 sr=SR, max_len=MAX_LEN, test_mode=False):\n        self.noisy_files = sorted(glob.glob(os.path.join(noisy_dir, '*.wav')))\n        self.clean_files = sorted(glob.glob(os.path.join(clean_dir, '*.wav')))\n        assert len(self.noisy_files) == len(self.clean_files), \\\n            f'Mismatch: {len(self.noisy_files)} noisy vs {len(self.clean_files)} clean'\n        # Verify filenames match\n        for nf, cf in zip(self.noisy_files[:3], self.clean_files[:3]):\n            assert os.path.basename(nf) == os.path.basename(cf), \\\n                f'Name mismatch: {os.path.basename(nf)} vs {os.path.basename(cf)}'\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.sr = sr\n        self.max_len = max_len\n        self.test_mode = test_mode\n        self.window = torch.hann_window(n_fft)\n\n    def __len__(self):\n        return len(self.noisy_files)\n\n    def __getitem__(self, idx):\n        # Load BOTH files\n        noisy_wav, sr_n = torchaudio.load(self.noisy_files[idx])\n        clean_wav, sr_c = torchaudio.load(self.clean_files[idx])\n        noisy_wav = noisy_wav[0]  # mono\n        clean_wav = clean_wav[0]\n\n        # Resample if needed\n        if sr_n != self.sr:\n            noisy_wav = torchaudio.functional.resample(noisy_wav, sr_n, self.sr)\n        if sr_c != self.sr:\n            clean_wav = torchaudio.functional.resample(clean_wav, sr_c, self.sr)\n\n        # Ensure same length (trim to shorter)\n        min_len = min(noisy_wav.shape[0], clean_wav.shape[0])\n        noisy_wav = noisy_wav[:min_len]\n        clean_wav = clean_wav[:min_len]\n\n        # ── CRITICAL FIX: ONE shared crop for both ──\n        if min_len > self.max_len:\n            if self.test_mode:\n                start = 0                # deterministic for evaluation\n            else:\n                start = torch.randint(0, min_len - self.max_len, (1,)).item()\n            noisy_wav = noisy_wav[start:start + self.max_len]\n            clean_wav = clean_wav[start:start + self.max_len]\n        elif min_len < self.max_len:\n            pad = self.max_len - min_len\n            noisy_wav = F.pad(noisy_wav, (0, pad))\n            clean_wav = F.pad(clean_wav, (0, pad))\n\n        # STFT\n        noisy_stft = torch.stft(noisy_wav, self.n_fft, self.hop_length,\n                                window=self.window, return_complex=True)\n        clean_stft = torch.stft(clean_wav, self.n_fft, self.hop_length,\n                                window=self.window, return_complex=True)\n        return {\n            'noisy_mag':   noisy_stft.abs(),\n            'clean_mag':   clean_stft.abs(),\n            'noisy_phase': torch.angle(noisy_stft),\n            'noisy_wav':   noisy_wav,\n            'clean_wav':   clean_wav,\n        }\n\n# Quick sanity check\n_ds = STFTSpeechDataset(noisy_test, clean_test, test_mode=True)\n_s = _ds[0]\nprint(f'STFTSpeechDataset v2 (aligned crops)')\nprint(f'  noisy_mag:  {_s[\"noisy_mag\"].shape}')\nprint(f'  clean_mag:  {_s[\"clean_mag\"].shape}')\nprint(f'  noisy_wav:  {_s[\"noisy_wav\"].shape}')\n\n# Verify alignment: noisy and clean should correlate\n_corr = torch.corrcoef(torch.stack([_s['noisy_wav'], _s['clean_wav']]))[0,1].item()\nprint(f'  noisy-clean correlation: {_corr:.4f}  (should be > 0.3 if aligned)')\nassert _corr > 0.1, f'Correlation too low ({_corr:.4f}) — crops may still be misaligned!'\nprint('  ALIGNMENT CHECK PASSED')\ndel _ds, _s"}, {"cell_type": "markdown", "id": "md06", "metadata": {"trusted": true}, "source": "## CRN Model\n\nSame architecture as v1 — the bug was in data loading, not the model.\n\n```\nCNN Encoder: (B, 1, 257, T)\n  -> Conv2d(1->64, stride=(2,1)) -> (B, 64, 129, T)\n  -> Conv2d(64->128, stride=(2,1)) -> (B, 128, 65, T)\n  -> Conv2d(128->256, stride=(2,1)) -> (B, 256, 33, T)\nLSTM: reshape to (B*33, T, 256) -> LSTM(256, 256, 2 layers)\nCNN Decoder: stride-2 transposed convolutions back to (B, 32, 257, T)\n  -> Conv2d(32->1, 1x1) + Sigmoid -> mask (B, 1, 257, T)\n```"}, {"cell_type": "code", "execution_count": null, "id": "c07", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 4: CRN Model (same architecture as v1)\n# ============================================================================\nclass CRNBaseline(nn.Module):\n    def __init__(self, n_freq=257):\n        super().__init__()\n        self.n_freq = n_freq\n        # CNN Encoder\n        self.enc1 = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, stride=(2, 1), padding=1),\n            nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n        self.enc2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=(2, 1), padding=1),\n            nn.BatchNorm2d(128), nn.ReLU(inplace=True))\n        self.enc3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=(2, 1), padding=1),\n            nn.BatchNorm2d(256), nn.ReLU(inplace=True))\n        # LSTM\n        self.lstm = nn.LSTM(input_size=256, hidden_size=256, num_layers=2,\n                            batch_first=True, dropout=0.1)\n        # CNN Decoder\n        self.dec3 = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=(2, 1), padding=1, output_padding=(1, 0)),\n            nn.BatchNorm2d(128), nn.ReLU(inplace=True))\n        self.dec2 = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=(2, 1), padding=1, output_padding=(1, 0)),\n            nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n        self.dec1 = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=(2, 1), padding=1, output_padding=(1, 0)),\n            nn.BatchNorm2d(32), nn.ReLU(inplace=True))\n        self.mask_conv = nn.Sequential(nn.Conv2d(32, 1, kernel_size=1), nn.Sigmoid())\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n                if m.bias is not None: nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.LSTM):\n                for name, param in m.named_parameters():\n                    if 'weight' in name: nn.init.xavier_normal_(param)\n                    elif 'bias' in name: nn.init.zeros_(param)\n\n    def forward(self, x):\n        B, _, F_orig, T_orig = x.shape\n        e1 = self.enc1(x)\n        e2 = self.enc2(e1)\n        e3 = self.enc3(e2)\n        B2, C, Fenc, T = e3.shape\n        lstm_in = e3.permute(0, 2, 3, 1).reshape(B2 * Fenc, T, C)\n        lstm_out, _ = self.lstm(lstm_in)\n        h = lstm_out.reshape(B2, Fenc, T, C).permute(0, 3, 1, 2)\n        d3 = self.dec3(h)\n        d2 = self.dec2(d3)\n        d1 = self.dec1(d2)\n        if d1.shape[2] != F_orig:\n            d1 = F.interpolate(d1, size=(F_orig, T_orig), mode='bilinear', align_corners=False)\n        mask = self.mask_conv(d1).squeeze(1)\n        return mask\n\nmodel = CRNBaseline(n_freq=N_FREQ).to(device)\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'CRNBaseline: {total_params:,} params ({total_params/1e6:.2f}M)')\n\nwith torch.no_grad():\n    dummy = torch.randn(2, 1, N_FREQ, 188).to(device)\n    mask = model(dummy)\n    print(f'Input: {dummy.shape} -> Mask: {mask.shape}')\n    assert mask.shape == (2, N_FREQ, 188), f'Shape mismatch: {mask.shape}'\n    assert mask.min().item() >= 0 and mask.max().item() <= 1\n    print(f'Mask range: [{mask.min().item():.4f}, {mask.max().item():.4f}]')\n    print('Forward pass OK')\n\nenc_p = sum(p.numel() for n, p in model.named_parameters() if 'enc' in n)\nlstm_p = sum(p.numel() for n, p in model.named_parameters() if 'lstm' in n)\ndec_p = sum(p.numel() for n, p in model.named_parameters() if 'dec' in n or 'mask_conv' in n)\nprint(f'  Encoder:  {enc_p:>10,} ({enc_p/total_params*100:.1f}%)')\nprint(f'  LSTM:     {lstm_p:>10,} ({lstm_p/total_params*100:.1f}%)')\nprint(f'  Decoder:  {dec_p:>10,} ({dec_p/total_params*100:.1f}%)')"}, {"cell_type": "code", "execution_count": null, "id": "c08", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 5: SI-SDR utility\n# ============================================================================\ndef si_sdr(estimate, reference):\n    ref = reference - reference.mean()\n    est = estimate  - estimate.mean()\n    dot = torch.sum(ref * est)\n    s_target = dot * ref / (torch.sum(ref**2) + 1e-8)\n    e_noise  = est - s_target\n    return 10 * torch.log10(torch.sum(s_target**2) / (torch.sum(e_noise**2) + 1e-8) + 1e-8)\n\nprint('si_sdr defined')"}, {"cell_type": "markdown", "id": "md09", "metadata": {"trusted": true}, "source": "## Training\nL1 loss on log-magnitude. Adam lr=1e-3 with ReduceLROnPlateau.\n**Now with aligned crops** — model sees matched (noisy, clean) pairs for the first time!"}, {"cell_type": "code", "execution_count": null, "id": "c10", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 6: Training setup\n# ============================================================================\nMAX_EPOCHS    = 30\nLR            = 1e-3\nBATCH         = 16\nPATIENCE      = 10\nCKPT          = 'crn_v2_best.pth'\n\nmodel = CRNBaseline(n_freq=N_FREQ).to(device)\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'Params: {total_params:,}')\n\n# Training dataset: test_mode=False (random aligned crops)\nfull_train = STFTSpeechDataset(noisy_train, clean_train, test_mode=False)\nn_val   = int(0.1 * len(full_train))\nn_train = len(full_train) - n_val\ntrain_ds, val_ds = torch.utils.data.random_split(\n    full_train, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n\n# Test dataset: test_mode=True (deterministic crop at start=0)\ntest_ds = STFTSpeechDataset(noisy_test, clean_test, test_mode=True)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n                          num_workers=0, drop_last=True)\nval_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=0)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, 'min', factor=0.5, patience=5)\n\nprint(f'Train:{n_train} Val:{n_val} Test:{len(test_ds)} | BS={BATCH} LR={LR}')\nprint(f'Train crops: RANDOM aligned | Test crops: DETERMINISTIC (start=0)')"}, {"cell_type": "code", "execution_count": null, "id": "c11", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 7: Training loop\n# ============================================================================\nhistory = {'train_loss': [], 'val_loss': []}\nbest_val = float('inf')\npatience_ctr = 0\nt0 = time.time()\n\nfor epoch in range(1, MAX_EPOCHS + 1):\n    # --- Train ---\n    model.train()\n    train_losses = []\n    for batch in tqdm(train_loader, desc=f'Ep{epoch}/{MAX_EPOCHS}', leave=False):\n        noisy_mag = batch['noisy_mag'].to(device)\n        clean_mag = batch['clean_mag'].to(device)\n        inp  = torch.log1p(noisy_mag).unsqueeze(1)   # (B, 1, 257, T)\n        mask = model(inp)                              # (B, 257, T)\n        enhanced_mag = mask * noisy_mag\n        loss = F.l1_loss(torch.log1p(enhanced_mag), torch.log1p(clean_mag))\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        optimizer.step()\n        train_losses.append(loss.item())\n\n    # --- Validate ---\n    model.eval()\n    val_losses = []\n    with torch.no_grad():\n        for batch in val_loader:\n            noisy_mag = batch['noisy_mag'].to(device)\n            clean_mag = batch['clean_mag'].to(device)\n            inp  = torch.log1p(noisy_mag).unsqueeze(1)\n            mask = model(inp)\n            enhanced_mag = mask * noisy_mag\n            loss = F.l1_loss(torch.log1p(enhanced_mag), torch.log1p(clean_mag))\n            val_losses.append(loss.item())\n\n    tr_loss = np.mean(train_losses)\n    va_loss = np.mean(val_losses)\n    history['train_loss'].append(tr_loss)\n    history['val_loss'].append(va_loss)\n    scheduler.step(va_loss)\n\n    elapsed = time.time() - t0\n    lr_now  = optimizer.param_groups[0]['lr']\n    line = f'Ep{epoch:02d} tr={tr_loss:.4f} va={va_loss:.4f} lr={lr_now:.1e} [{elapsed:.0f}s]'\n\n    if va_loss < best_val:\n        best_val = va_loss\n        patience_ctr = 0\n        torch.save({'epoch': epoch, 'model': model.state_dict(),\n                     'val_loss': float(va_loss)}, CKPT)\n        print(f'{line}  SAVED best={va_loss:.4f}')\n    else:\n        patience_ctr += 1\n        print(f'{line}  no improve ({patience_ctr}/{PATIENCE})')\n\n    if epoch % 5 == 0:\n        torch.save(model.state_dict(), f'ckpt_ep{epoch}.pth')\n\n    if patience_ctr >= PATIENCE:\n        print(f'Early stopping at epoch {epoch}')\n        break\n\nbest_ep = history['val_loss'].index(min(history['val_loss'])) + 1\nprint(f'\\nDONE best_ep={best_ep} best_val={best_val:.4f} time={time.time()-t0:.0f}s')"}, {"cell_type": "markdown", "id": "md12", "metadata": {"trusted": true}, "source": "## Results"}, {"cell_type": "code", "execution_count": null, "id": "c13", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 8: Training curves\n# ============================================================================\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\neps = range(1, len(history['train_loss']) + 1)\nax.plot(eps, history['train_loss'], 'b-o', label='Train', ms=3)\nax.plot(eps, history['val_loss'], 'r-s', label='Val', ms=3)\nax.axvline(best_ep, color='g', ls='--', alpha=0.7, label=f'Best (ep{best_ep})')\nax.set_xlabel('Epoch')\nax.set_ylabel('L1 Loss (log-magnitude)')\nax.set_title('CRN v2 (Aligned Crops) — Training Curves')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=150)\nplt.show()\nprint('Saved training_curves.png')"}, {"cell_type": "markdown", "id": "md14", "metadata": {"trusted": true}, "source": "## Evaluation\nPESQ / STOI / SI-SDR on 105 test samples.\n**Deterministic:** test_mode=True → crop at start=0 → same segment every run."}, {"cell_type": "code", "execution_count": null, "id": "c15", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 9: Evaluation — PESQ / STOI / SI-SDR\n# ============================================================================\ntorch.manual_seed(42)   # extra safety for determinism\n\nckpt = torch.load(CKPT, map_location=device, weights_only=False)\nmodel.load_state_dict(ckpt['model'])\nmodel.eval()\nprint(f'Loaded: epoch={ckpt[\"epoch\"]}, val_loss={ckpt[\"val_loss\"]:.4f}')\n\nwindow_eval = torch.hann_window(N_FFT).to(device)\n\npesq_noisy_list, pesq_enh_list   = [], []\nstoi_noisy_list, stoi_enh_list   = [], []\nsisdr_noisy_list, sisdr_enh_list = [], []\n\nfor i in tqdm(range(len(test_ds)), desc='Eval'):\n    s           = test_ds[i]\n    noisy_mag   = s['noisy_mag'].unsqueeze(0).to(device)\n    noisy_phase = s['noisy_phase'].unsqueeze(0).to(device)\n    clean_np    = s['clean_wav'].numpy()\n    noisy_np    = s['noisy_wav'].numpy()\n\n    with torch.no_grad():\n        inp     = torch.log1p(noisy_mag).unsqueeze(1)\n        mask    = model(inp)\n        enh_mag = (mask * noisy_mag).squeeze(0)\n\n    enh_stft = enh_mag * torch.exp(1j * noisy_phase.squeeze(0))\n    enh_wav  = torch.istft(enh_stft, N_FFT, HOP_LENGTH,\n                           window=window_eval, length=MAX_LEN)\n    enh_np   = enh_wav.cpu().numpy()\n\n    try:\n        pesq_noisy_list.append(pesq_metric(SR, clean_np, noisy_np, 'wb'))\n        pesq_enh_list.append(  pesq_metric(SR, clean_np, enh_np,   'wb'))\n    except Exception as e:\n        print(f'  PESQ err {i}: {e}')\n\n    stoi_noisy_list.append(stoi_metric(clean_np, noisy_np, SR, extended=False))\n    stoi_enh_list.append(  stoi_metric(clean_np, enh_np,   SR, extended=False))\n\n    c_t = torch.from_numpy(clean_np).float()\n    n_t = torch.from_numpy(noisy_np).float()\n    e_t = torch.from_numpy(enh_np).float()\n    sisdr_noisy_list.append(si_sdr(n_t, c_t).item())\n    sisdr_enh_list.append(  si_sdr(e_t, c_t).item())\n\n    if i < 3:\n        print(f'  [{i}] PESQ: {pesq_noisy_list[-1]:.3f}->{pesq_enh_list[-1]:.3f}  '\n              f'STOI: {stoi_noisy_list[-1]:.3f}->{stoi_enh_list[-1]:.3f}  '\n              f'SI-SDR: {sisdr_noisy_list[-1]:.2f}->{sisdr_enh_list[-1]:.2f}dB')\n\navg = lambda lst: float(np.mean(lst)) if lst else 0.0\navg_pesq_n,  avg_pesq_e  = avg(pesq_noisy_list),  avg(pesq_enh_list)\navg_stoi_n,  avg_stoi_e  = avg(stoi_noisy_list),  avg(stoi_enh_list)\navg_sisdr_n, avg_sisdr_e = avg(sisdr_noisy_list), avg(sisdr_enh_list)\n\nprint(f'\\n{\"=\"*70}')\nprint(f'Results on {len(test_ds)} test files (ALIGNED deterministic crops):')\nprint(f'  PESQ  : noisy={avg_pesq_n:.3f}  enhanced={avg_pesq_e:.3f}  Δ={avg_pesq_e-avg_pesq_n:+.3f}')\nprint(f'  STOI  : noisy={avg_stoi_n:.3f}  enhanced={avg_stoi_e:.3f}  Δ={avg_stoi_e-avg_stoi_n:+.4f}')\nprint(f'  SI-SDR: noisy={avg_sisdr_n:.2f}dB  enh={avg_sisdr_e:.2f}dB  Δ={avg_sisdr_e-avg_sisdr_n:+.2f}dB')\nprint(f'{\"=\"*70}')"}, {"cell_type": "markdown", "id": "md16", "metadata": {"trusted": true}, "source": "## Visualization\nSpectrogram comparison: noisy vs enhanced vs clean, plus predicted mask."}, {"cell_type": "code", "execution_count": null, "id": "c17", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 10: Spectrogram comparison\n# ============================================================================\nsample = test_ds[0]\nnoisy_mag_s = sample['noisy_mag'].unsqueeze(0).to(device)\n\nwith torch.no_grad():\n    inp_s  = torch.log1p(noisy_mag_s).unsqueeze(1)\n    mask_s = model(inp_s)\n    enh_mag_s = (mask_s * noisy_mag_s).squeeze(0).cpu()\n\nnoisy_spec = sample['noisy_mag'].numpy()\nclean_spec = sample['clean_mag'].numpy()\nenh_spec   = enh_mag_s.numpy()\nmask_np    = mask_s.squeeze(0).cpu().numpy()\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfor ax, spec, title in [\n    (axes[0,0], np.log1p(noisy_spec), 'Noisy Input'),\n    (axes[0,1], np.log1p(clean_spec), 'Clean Target'),\n    (axes[1,0], np.log1p(enh_spec),   'Enhanced (CRN v2)'),\n    (axes[1,1], mask_np,              'Predicted Mask'),\n]:\n    im = ax.imshow(spec, aspect='auto', origin='lower', cmap='viridis')\n    ax.set_title(title, fontsize=13)\n    ax.set_xlabel('Time frame')\n    ax.set_ylabel('Frequency bin')\n    plt.colorbar(im, ax=ax, fraction=0.046)\n\nplt.suptitle('CRN v2 (Aligned Crops): Spectrogram Comparison', fontsize=14)\nplt.tight_layout()\nplt.savefig('spectrogram_comparison.png', dpi=150)\nplt.show()\nprint('Saved spectrogram_comparison.png')"}, {"cell_type": "code", "execution_count": null, "id": "c18", "metadata": {"trusted": true}, "outputs": [], "source": "# ============================================================================\n# Cell 11: Summary JSON + comparison table\n# ============================================================================\nsummary = {\n    'model': 'CRN_v2_AlignedCrops',\n    'architecture': 'CRNBaseline (LSTM-based)',\n    'critical_fix': 'Aligned random crops for noisy/clean pairs',\n    'params': total_params,\n    'checkpoint': {'epoch': int(ckpt['epoch']), 'val_loss': float(ckpt['val_loss'])},\n    'test_samples': len(test_ds),\n    'metrics': {\n        'pesq_noisy':        round(avg_pesq_n, 3),\n        'pesq_enhanced':     round(avg_pesq_e, 3),\n        'stoi_noisy':        round(avg_stoi_n, 4),\n        'stoi_enhanced':     round(avg_stoi_e, 4),\n        'sisdr_noisy_dB':    round(avg_sisdr_n, 2),\n        'sisdr_enhanced_dB': round(avg_sisdr_e, 2),\n    },\n    'history': history,\n}\nwith open('crn_v2_summary.json', 'w') as f:\n    json.dump(summary, f, indent=2)\nprint('Saved crn_v2_summary.json')\n\nW = 70\nprint(f'\\n{\"=\"*W}')\nprint(f'{\"Metric\":>10} {\"Noisy\":>12} {\"CRN v2\":>12} {\"Delta\":>12}')\nprint(f'{\"=\"*W}')\nprint(f'{\"PESQ\":>10} {avg_pesq_n:>12.3f} {avg_pesq_e:>12.3f} {avg_pesq_e-avg_pesq_n:>+12.3f}')\nprint(f'{\"STOI\":>10} {avg_stoi_n:>12.3f} {avg_stoi_e:>12.3f} {avg_stoi_e-avg_stoi_n:>+12.4f}')\nprint(f'{\"SI-SDR\":>10} {avg_sisdr_n:>11.2f}dB {avg_sisdr_e:>11.2f}dB {avg_sisdr_e-avg_sisdr_n:>+11.2f}dB')\nprint(f'{\"=\"*W}')\nprint(f'\\nv1 (misaligned) noisy baseline was: STOI=0.215, SI-SDR=-44dB (broken)')\nprint(f'v2 (aligned) noisy baseline is: STOI={avg_stoi_n:.3f}, SI-SDR={avg_sisdr_n:.2f}dB (correct)')"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10.0"}}, "nbformat": 4, "nbformat_minor": 5}